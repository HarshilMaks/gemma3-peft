{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ghost Architect — Colab T4 Main Notebook\n",
    "\n",
    "This is the single notebook to run full **Gemma-3 Trinity training** on Google Colab T4 (16GB).\n",
    "\n",
    "## What this notebook does\n",
    "1. Validates T4 runtime\n",
    "2. Installs exact dependencies\n",
    "3. Syncs project files\n",
    "4. Writes full T4 training configuration\n",
    "5. Launches training\n",
    "6. Exports GGUF artifacts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Runtime Check (must be T4 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d031deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4\n",
      "VRAM: 14.6 GB\n",
      "Wed Feb 25 08:16:16 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   48C    P8             11W /   70W |       3MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available(), 'CUDA is not available. Set Runtime > GPU in Colab.'\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "gpu_mem_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "print(f'GPU: {gpu_name}')\n",
    "print(f'VRAM: {gpu_mem_gb:.1f} GB')\n",
    "if 'T4' not in gpu_name:\n",
    "    print('Warning: This notebook is tuned for T4; adjust config if using a different GPU.')\n",
    "\n",
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26557e55",
   "metadata": {},
   "source": [
    "## 2) Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8d8b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hNo broken requirements found.\n",
      "Dependencies installed. xformers is optional and intentionally not force-installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q --retries 10 --timeout 120 --upgrade pip setuptools wheel \"jedi>=0.16\"\n",
    "!pip install -q --retries 10 --timeout 120 \"unsloth==2026.1.4\"\n",
    "!pip install -q --retries 10 --timeout 120 \"trl>=0.18.2,<=0.24.0,!=0.19.0\"\n",
    "!pip install -q --retries 10 --timeout 120 peft accelerate bitsandbytes datasets numpy scipy tqdm\n",
    "!pip install -q --retries 10 --timeout 120 \"torch>=2.1.0\" \"transformers>=4.38.0\"\n",
    "!pip check || true\n",
    "\n",
    "print('Dependencies installed. xformers is optional and intentionally not force-installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a14e54",
   "metadata": {},
   "source": [
    "## 3) Mount Drive and Sync Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c891cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘/content/drive/MyDrive’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!find /content/drive/MyDrive -maxdepth 6 -type f -path \"*/src/train_vision.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f660fe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/ghost_architect_gemma3\n",
      "✅ Success! Current working directory: /content/drive/MyDrive/ghost_architect_gemma3\n",
      "\n",
      "Folder contents:\n",
      "configs  data  src\n",
      "\n",
      "✅ 'src/train_vision.py' found. Ready for training!\n"
     ]
    }
   ],
   "source": [
    "# 3) Mount Drive and Enter Project Folder\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the path to your project in Drive\n",
    "# NOTE: Ensure you uploaded the folder named 'ghost_architect_gemma3' to your Drive root\n",
    "PROJECT_DIR = '/content/drive/MyDrive/ghost_architect_gemma3'\n",
    "\n",
    "# Check if the folder exists before trying to enter it\n",
    "if not os.path.exists(PROJECT_DIR):\n",
    "    print(f\"❌ Error: Could not find project at {PROJECT_DIR}\")\n",
    "    print(\"Please make sure you dragged the 'ghost_architect_gemma3' folder to the main 'My Drive' screen.\")\n",
    "    print(\"Listing folders in your Drive to help debug:\")\n",
    "    !ls /content/drive/MyDrive | head -n 10\n",
    "else:\n",
    "    # Change directory directly INTO the Drive folder\n",
    "    %cd {PROJECT_DIR}\n",
    "    \n",
    "    # Verify we are in the right place\n",
    "    print(f\"✅ Success! Current working directory: {os.getcwd()}\")\n",
    "    print(\"\\nFolder contents:\")\n",
    "    !ls\n",
    "    \n",
    "    # Verify the critical Vision Trainer exists\n",
    "    if os.path.exists('src/train_vision.py'):\n",
    "        print(\"\\n✅ 'src/train_vision.py' found. Ready for training!\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Warning: 'src/train_vision.py' not found. Did you upload the 'src' folder?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350dcba",
   "metadata": {},
   "source": [
    "## 3.5) Environment Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a789b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/content/drive/MyDrive/ghost_architect_gemma3/scripts/validate_environment.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python scripts/validate_environment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06865c9c",
   "metadata": {},
   "source": [
    "## 4) Full T4 Trinity Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da84101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote configs/training_config_colab_t4.yaml\n"
     ]
    }
   ],
   "source": [
    "config_yaml = '''\n",
    "model_name: \"unsloth/gemma-3-12b-it-bnb-4bit\"\n",
    "max_seq_length: 4096\n",
    "load_in_4bit: true\n",
    "\n",
    "lora:\n",
    "  r: 64\n",
    "  lora_alpha: 32\n",
    "  target_modules:\n",
    "    - q_proj\n",
    "    - k_proj\n",
    "    - v_proj\n",
    "    - o_proj\n",
    "    - gate_proj\n",
    "    - up_proj\n",
    "    - down_proj\n",
    "  use_rslora: true\n",
    "  use_dora: true\n",
    "  lora_dropout: 0.1\n",
    "\n",
    "training:\n",
    "  per_device_train_batch_size: 1\n",
    "  gradient_accumulation_steps: 4\n",
    "  learning_rate: 2e-4\n",
    "  max_steps: 60\n",
    "  warmup_steps: 10\n",
    "  logging_steps: 1\n",
    "  save_steps: 20\n",
    "  optimizer: \"adamw_8bit\"\n",
    "  lr_scheduler_type: \"cosine\"\n",
    "\n",
    "output:\n",
    "  adapters_dir: \"output/adapters\"\n",
    "  checkpoints_dir: \"output/checkpoints\"\n",
    "  gguf_dir: \"output/gguf\"\n",
    "\n",
    "oom_fallbacks:\n",
    "  - {action: reduce_seq_len, value: 2048}\n",
    "  - {action: reduce_rank, value: 32}\n",
    "  - {action: disable_dora, value: false}\n",
    "'''\n",
    "\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "with open('configs/training_config_colab_t4.yaml', 'w') as f:\n",
    "    f.write(config_yaml)\n",
    "\n",
    "print('Wrote configs/training_config_colab_t4.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48880cd5",
   "metadata": {},
   "source": [
    "## 5) Validate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e51c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset JSON is valid.\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "dataset_path = 'data/dataset.json'\n",
    "assert os.path.exists(dataset_path), f'Missing dataset: {dataset_path}'\n",
    "\n",
    "with open(dataset_path, 'r') as f:\n",
    "    raw = f.read().strip()\n",
    "\n",
    "if raw:\n",
    "    _ = json.loads(raw)\n",
    "    print('Dataset JSON is valid.')\n",
    "else:\n",
    "    print('Dataset file is empty. Populate data/dataset.json before training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f015f69",
   "metadata": {},
   "source": [
    "## 6) Launch Full Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9879bcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-25 08:25:39.939868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1772007939.960673    3767 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1772007939.967457    3767 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1772007939.985208    3767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1772007939.985231    3767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1772007939.985235    3767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1772007939.985241    3767 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2026-02-25 08:25:39.989748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading Multimodal Processor...\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 403, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/requests/models.py\", line 1026, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-3-12b-it/resolve/main/config.json\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 479, in cached_files\n",
      "    hf_hub_download(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1014, in hf_hub_download\n",
      "    return _hf_hub_download_to_cache_dir(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1121, in _hf_hub_download_to_cache_dir\n",
      "    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1662, in _raise_on_head_call_error\n",
      "    raise head_call_error\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1550, in _get_metadata_or_catch_error\n",
      "    metadata = get_hf_file_metadata(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 1467, in get_hf_file_metadata\n",
      "    r = _request_wrapper(\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 283, in _request_wrapper\n",
      "    response = _request_wrapper(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\", line 307, in _request_wrapper\n",
      "    hf_raise_for_status(response)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 420, in hf_raise_for_status\n",
      "    raise _format(GatedRepoError, message, response) from e\n",
      "huggingface_hub.errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-699eb210-2a98bd9f6d1d1b9c339bebbe;c8e01b1d-5049-4aac-b880-199df8d2714b)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/google/gemma-3-12b-it/resolve/main/config.json.\n",
      "Access to model google/gemma-3-12b-it is restricted. You must have access to it and be authenticated to access it. Please log in.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/drive/MyDrive/ghost_architect_gemma3/src/train_vision.py\", line 105, in <module>\n",
      "    run_vision_training(args.dataset)\n",
      "  File \"/content/drive/MyDrive/ghost_architect_gemma3/src/train_vision.py\", line 50, in run_vision_training\n",
      "    processor = AutoProcessor.from_pretrained(model_id)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/processing_auto.py\", line 363, in from_pretrained\n",
      "    config = AutoConfig.from_pretrained(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/auto/configuration_auto.py\", line 1332, in from_pretrained\n",
      "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 662, in get_config_dict\n",
      "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/configuration_utils.py\", line 721, in _get_config_dict\n",
      "    resolved_config_file = cached_file(\n",
      "                           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 322, in cached_file\n",
      "    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\", line 543, in cached_files\n",
      "    raise OSError(\n",
      "OSError: You are trying to access a gated repo.\n",
      "Make sure to have access to it at https://huggingface.co/google/gemma-3-12b-it.\n",
      "401 Client Error. (Request ID: Root=1-699eb210-2a98bd9f6d1d1b9c339bebbe;c8e01b1d-5049-4aac-b880-199df8d2714b)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/google/gemma-3-12b-it/resolve/main/config.json.\n",
      "Access to model google/gemma-3-12b-it is restricted. You must have access to it and be authenticated to access it. Please log in.\n"
     ]
    }
   ],
   "source": [
    "!python src/train_vision.py --dataset data/dataset.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Export to GGUF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected CLI in future implementation:\n",
    "# !python src/export.py --adapter_dir output/adapters --output_dir output/gguf --quantization q4_k_m\n",
    "\n",
    "print('Implement src/export.py next, then run the command above.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
